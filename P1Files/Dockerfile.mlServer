# Use a base image with the necessary ML libraries (modify according to your needs)
FROM tensorflow/tensorflow:2.10.0

# Set working directory
WORKDIR /app

# Copy the requirements file
COPY requirements.txt .

# Install dependencies
RUN pip install -r requirements.txt

# Copy the inference server code and model files
COPY mlServer.py .

# Expose the port for the ML inference server
EXPOSE 8080

# Command to run the inference server
CMD ["python", "mlServer.py"]
